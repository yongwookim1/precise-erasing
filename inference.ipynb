{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8301596-d405-4d6d-a86d-4c0060da77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fc005",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20\n",
    "seed = 41\n",
    "lora_rank = 8\n",
    "erased_prompt = \"VanGogh\".lower()\n",
    "prompt = \"Van Gogh style dog\"\n",
    "remain_prompt = \"A dog\"\n",
    "device = \"cuda:2\"\n",
    "train_method = \"xattn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac7476-6b52-4d49-b044-4bc3a84fe849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "esd_path = f'./models/esd-{erased_prompt}_from_{erased_prompt}-{train_method}_1-epochs_{iterations}.pt'\n",
    "\n",
    "diffuser = StableDiffuser(scheduler='DDIM').to(device)\n",
    "\n",
    "finetuner = FineTunedModel(diffuser, train_method=train_method, lora_rank=lora_rank)\n",
    "finetuner.load_state_dict(torch.load(esd_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77386f14-35a7-43d3-bbc9-c6fede9c8fca",
   "metadata": {},
   "source": [
    "## Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb0941-24bb-41af-991d-a271a0406b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_origin_image = diffuser(prompt,\n",
    "         img_size=512,\n",
    "         n_steps=50,\n",
    "         n_imgs=1,\n",
    "         generator=torch.Generator().manual_seed(seed),\n",
    "         guidance_scale=7.5\n",
    "         )[0][0]\n",
    "forget_origin_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50941070",
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_origin_image = diffuser(remain_prompt,\n",
    "         img_size=512,\n",
    "         n_steps=50,\n",
    "         n_imgs=1,\n",
    "         generator=torch.Generator().manual_seed(seed),\n",
    "         guidance_scale=7.5\n",
    "         )[0][0]\n",
    "retain_origin_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb2d3e7-e8be-4c9f-ad40-2396d02d3752",
   "metadata": {},
   "source": [
    "## Erased Model (Full fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e84c33-93ca-4e88-8399-3d83279f1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with finetuner:\n",
    "    forget_image = diffuser(prompt,\n",
    "             img_size=512,\n",
    "             n_steps=50,\n",
    "             n_imgs=1,\n",
    "             generator=torch.Generator().manual_seed(seed),\n",
    "             guidance_scale=7.5\n",
    "             )[0][0]\n",
    "forget_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd36dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with finetuner:\n",
    "    retain_image = diffuser(remain_prompt,\n",
    "             img_size=512,\n",
    "             n_steps=50,\n",
    "             n_imgs=1,\n",
    "             generator=torch.Generator().manual_seed(seed),\n",
    "             guidance_scale=7.5\n",
    "             )[0][0]\n",
    "retain_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb886a87",
   "metadata": {},
   "source": [
    "## Erased Model (LoRA Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "esd_path = f'./models/esd-{erased_prompt}_from_{erased_prompt}-{train_method}_1-epochs_{iterations}_lora_rank_{lora_rank}.pt'\n",
    "\n",
    "finetuner = FineTunedModel.from_checkpoint(model=diffuser,\n",
    "                                           checkpoint=esd_path,\n",
    "                                           train_method=train_method,\n",
    "                                           lora_rank=lora_rank,\n",
    "                                           lora_alpha=1.0,\n",
    "                                           )\n",
    "\n",
    "with finetuner:\n",
    "    forget_lora_image = diffuser(prompt,\n",
    "             img_size=512,\n",
    "             n_steps=50,\n",
    "             n_imgs=1,\n",
    "             generator=torch.Generator().manual_seed(seed),\n",
    "             guidance_scale=7.5\n",
    "             )[0][0]\n",
    "forget_lora_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with finetuner:\n",
    "    retain_lora_image = diffuser(remain_prompt,\n",
    "             img_size=512,\n",
    "             n_steps=50,\n",
    "             n_imgs=1,\n",
    "             generator=torch.Generator().manual_seed(seed),\n",
    "             guidance_scale=7.5\n",
    "             )[0][0]\n",
    "retain_lora_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f4a10",
   "metadata": {},
   "source": [
    "## SLoU (Steered Low-rank Unlearning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c207ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "esd_path = f'./models/esd-{erased_prompt}_from_{erased_prompt}-{train_method}_1-epochs_{iterations}_lora_rank_{lora_rank}_init.pt'\n",
    "\n",
    "finetuner = FineTunedModel.from_checkpoint(model=diffuser,\n",
    "                                           checkpoint=esd_path,\n",
    "                                           train_method=train_method,\n",
    "                                           lora_rank=lora_rank,\n",
    "                                           lora_alpha=1.0,\n",
    "                                           lora_init_prompt=prompt,\n",
    "                                           )\n",
    "\n",
    "with finetuner:\n",
    "    forget_init_image = diffuser(prompt,\n",
    "             img_size=512,\n",
    "             n_steps=50,\n",
    "             n_imgs=1,\n",
    "             generator=torch.Generator().manual_seed(seed),\n",
    "             guidance_scale=7.5\n",
    "             )[0][0]\n",
    "forget_init_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with finetuner:\n",
    "    retain_init_image = diffuser(remain_prompt,\n",
    "             img_size=512,\n",
    "             n_steps=50,\n",
    "             n_imgs=1,\n",
    "             generator=torch.Generator().manual_seed(seed),\n",
    "             guidance_scale=7.5\n",
    "             )[0][0]\n",
    "retain_init_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(2, 4, 1)\n",
    "plt.imshow(forget_origin_image)\n",
    "plt.title('Original Model')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.imshow(forget_image)\n",
    "plt.title('Erased Model (Full)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.imshow(forget_lora_image)\n",
    "plt.title('Erased Model (LoRA)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "plt.imshow(forget_init_image)\n",
    "plt.title('SLoU')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 5)\n",
    "plt.imshow(retain_origin_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "plt.imshow(retain_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 7)\n",
    "plt.imshow(retain_lora_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 8)\n",
    "plt.imshow(retain_init_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e889c-d39f-4252-8413-a876686c0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(esd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed65f1-c6ea-4abf-b457-e25d8e100bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_state = diffuser.unet.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbef9d-5b83-4694-b2d0-740fbcac3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(original_state['d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa1081-a39a-4263-98bb-7276af9cee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [] \n",
    "changes = []\n",
    "for key, value in state_dict.items():\n",
    "    if key.split(\"_\")[0] != \"lora\":\n",
    "        original_value = original_state[f\"{key.replace('unet.','')}.weight\"]\n",
    "        edited_value = value['weight'].to(device)\n",
    "\n",
    "        change = (edited_value - original_value).norm()\n",
    "        \n",
    "        changes.append((change / original_value.norm()).item())\n",
    "        names.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bdd549-1eae-44f9-a50c-ac98fc9314e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_k(names, values, k=3):\n",
    "    # Sort and get top k\n",
    "    paired_lists = list(zip(names, values))\n",
    "    sorted_pairs = sorted(paired_lists, key=lambda x: x[1], reverse=True)[:k]\n",
    "    sorted_names, sorted_values = zip(*sorted_pairs)\n",
    "    \n",
    "    # Create bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(sorted_names, sorted_values)\n",
    "    plt.title(f'Top {k} Values')\n",
    "    plt.xlabel('Names')\n",
    "    plt.ylabel('Values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833489e4-fe98-482f-aa04-d6211dd38e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_k(names, changes, k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146acbc-8c5a-4a6b-a3f0-d261d4273ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
